import tvm
import numpy as np

from tvm import relay

def to_int_array(arr, param_values=None):
    if param_values is None:
        param_values = {}
    return [tvm.ir_pass.Simplify(tvm.ir_pass.Substitute(s, param_values)).value
            for s in arr]

def tvm2numpy(something):
    if isinstance(something, (tvm.ndarray.NDArray, relay.backend.interpreter.TensorValue)):
        return something.asnumpy()
    elif isinstance(something, list):
        return [tvm2numpy(s) for s in something]
    elif isinstance(something, (tuple, relay.backend.interpreter.TupleValue)):
        return tuple(tvm2numpy(s) for s in something)
    return something

def check_relay_grad(expr, in_range=(-10,10), acceptable_fail_fraction=None):
    expr = relay.ir_pass.infer_type(expr)
    if len(expr.checked_type.shape) != 0:
        expr = relay.op.sum(expr)

    input_vars = relay.ir_pass.free_vars(expr)
    func = relay.Function(input_vars, expr)
    func = relay.ir_pass.infer_type(func)

    gfunc = relay.ir_pass.gradient(func)
    gfunc = relay.ir_pass.infer_type(gfunc)

    executor = relay.create_executor()
    tvm_func = executor.evaluate(func)
    tvm_gfunc = executor.evaluate(gfunc)

    np_func = lambda *a: tvm2numpy(tvm_func(*a))
    np_gfunc = lambda *a: tvm2numpy(tvm_gfunc(*a))

    input_vals = [np.random.uniform(in_range[0], in_range[1],
                                    size=to_int_array(a.type_annotation.shape))
                  .astype(a.type_annotation.dtype)
                  for a in input_vars]

    tvm.testing.check_numerical_grads(np_func, input_vals, np_gfunc(*input_vals)[1],
                                      acceptable_fail_fraction=acceptable_fail_fraction)

def test_autogenerated_primal_gradients():
    relay._ir_pass.AutogeneratePrimalGradientForAll(100)

    x = relay.var("x", shape=(5,), dtype='float64')
    y = relay.var("y", shape=(5,), dtype='float64')

    check_relay_grad(x*x)
    check_relay_grad(x*y)
    check_relay_grad(x*y + x + y)

    k = relay.var("k", shape=())
    x = relay.var("x", shape=(5,))
    y = relay.var("y", shape=(5,))
    ix = relay.var("ix", shape=(5,), dtype='int32')
    iy = relay.var("iy", shape=(5,), dtype='int32')
    ind = relay.var("ind", shape=(10,), dtype='int32')
    x1 = relay.var("x1", shape=(5,))
    y1 = relay.var("y1", shape=(5,))
    X = relay.var("X", shape=(5, 7))
    Y = relay.var("Y", shape=(5, 10))
    Y1 = relay.var("Y1", shape=(1, 2, 5, 5))
    Y2 = relay.var("Y2", shape=(3, 2, 5, 5))
    W = relay.var("W", shape=(7, 10))
    A = relay.var("A", shape=(2, 5, 7, 7))
    w = relay.var("w", shape=(4, 5, 3, 3))
    w1 = relay.var("w1", shape=(5, 4, 3, 3))

    check_relay_grad(x*x)
    check_relay_grad(x*y)
    check_relay_grad(x*y + x + y)

    check_relay_grad(relay.op.log(x), in_range=(0.1, 10))
    check_relay_grad(relay.op.sqrt(x), in_range=(0.1, 10))
    check_relay_grad(relay.op.exp(x))
    check_relay_grad(relay.op.sigmoid(x))
    check_relay_grad(relay.op.add(x, y))
    check_relay_grad(relay.op.subtract(x, y))
    check_relay_grad(relay.op.multiply(x, y))
    check_relay_grad(relay.op.divide(x, y))
    #check_relay_grad(relay.op.mod(x, y))
    check_relay_grad(relay.op.tanh(x))
    #check_relay_grad(relay.op.concatenate([x, y], 0))
    #check_relay_grad(relay.op.concatenate([X, Y], 1))
    check_relay_grad(relay.op.expand_dims(X, 1, 1))
    check_relay_grad(relay.op.expand_dims(X, 2, 3))
    check_relay_grad(relay.nn.softmax(x))
    check_relay_grad(relay.nn.log_softmax(X))
    check_relay_grad(relay.nn.relu(x))
    #check_relay_grad(relay.nn.dropout(x))
    #check_relay_grad(relay.nn.batch_norm(A, x, y, x1, y1)[0])
    check_relay_grad(relay.nn.bias_add(X, x, 0))

    check_relay_grad(relay.nn.conv2d(A, w))
    check_relay_grad(relay.nn.conv2d(A, w, strides=(2, 1)))
    check_relay_grad(relay.nn.conv2d(A, w, padding=(1, 0)))
    check_relay_grad(relay.nn.conv2d(A, w, dilation=(1, 2)))
    check_relay_grad(relay.nn.conv2d_transpose(A, w1))
    check_relay_grad(relay.nn.conv2d_transpose(A, w1, strides=(2, 1)))
    check_relay_grad(relay.nn.conv2d_transpose(A, w1, padding=(1, 0)))
    #check_relay_grad(relay.nn.conv2d_transpose(A, w1, dilation=(1, 2)))
    check_relay_grad(relay.nn.dense(X, W))
    check_relay_grad(relay.nn.max_pool2d(A))
    check_relay_grad(relay.nn.max_pool2d(A, pool_size=(2, 2)))
    check_relay_grad(relay.nn.max_pool2d(A, pool_size=(2, 2), strides=(2, 1)))
    check_relay_grad(relay.nn.max_pool2d(A, pool_size=(3, 3), strides=(3, 2), padding=(1, 1)))
    check_relay_grad(relay.nn.avg_pool2d(A))
    check_relay_grad(relay.nn.avg_pool2d(A, pool_size=(2, 2)))
    check_relay_grad(relay.nn.avg_pool2d(A, pool_size=(2, 2), strides=(2, 1)))
    check_relay_grad(relay.nn.avg_pool2d(A, pool_size=(3, 3), strides=(3, 2), padding=(1, 1)))
    check_relay_grad(relay.nn.global_max_pool2d(A))
    check_relay_grad(relay.nn.global_avg_pool2d(A))
    check_relay_grad(relay.nn.upsampling(A, scale=2))
    check_relay_grad(relay.nn.batch_flatten(A))
    check_relay_grad(relay.nn.pad(A, ((0, 0), (0, 1), (1, 2), (2, 3))))
    check_relay_grad(relay.nn.lrn(A))
    check_relay_grad(relay.nn.l2_normalize(A, 0.01, axis=[1]))
    #check_relay_grad(relay.nn.contrib_conv2d_winograd_without_weight_transform(...))
    check_relay_grad(relay.nn.contrib_conv2d_winograd_weight_transform(w, 4))

    check_relay_grad(relay.nn.leaky_relu(x, 0.1))
    check_relay_grad(relay.nn.prelu(A, x))
    check_relay_grad(relay.reshape(Y, (2, 5, 5)))
    check_relay_grad(relay.reshape_like(Y, Y1))
    check_relay_grad(relay.copy(x))
    check_relay_grad(relay.transpose(Y))
    check_relay_grad(relay.squeeze(Y1))
    check_relay_grad(relay.floor(x), acceptable_fail_fraction=0.2)
    check_relay_grad(relay.ceil(x), acceptable_fail_fraction=0.2)
    check_relay_grad(relay.trunc(x), acceptable_fail_fraction=0.2)
    #check_relay_grad(relay.clip(x, -2, 2))
    check_relay_grad(relay.round(x), acceptable_fail_fraction=0.2)
    check_relay_grad(relay.abs(x))
    check_relay_grad(relay.negative(x))
    #check_relay_grad(relay.take(x, ind), in_range=(0, 4))
    check_relay_grad(relay.zeros((5, 6), 'float32'))
    check_relay_grad(relay.zeros_like(x))
    check_relay_grad(relay.ones((5, 6), 'float32'))
    check_relay_grad(relay.ones_like(x))
    check_relay_grad(relay.full(k, (5, 6), 'float32'))
    check_relay_grad(relay.full_like(x, k))
    #check_relay_grad(relay.cast(x, 'float64'))
    #check_relay_grad(relay.split(x, (1, 3)))

    #check_relay_grad(relay.right_shift(ix, iy))
    #check_relay_grad(relay.left_shift(ix, iy))
    #check_relay_grad(relay.equal(ix, iy))
    #check_relay_grad(relay.not_equal(ix, iy))
    #check_relay_grad(relay.greater(x, y))
    #check_relay_grad(relay.greater_equal(x, y))
    #check_relay_grad(relay.less(x, y))
    #check_relay_grad(relay.less_equal(x, y))
    check_relay_grad(relay.maximum(x, y))
    check_relay_grad(relay.minimum(x, y))
    check_relay_grad(relay.power(relay.abs(x), y))
    #check_relay_grad(relay.where(ix, x, y))
    #check_relay_grad(relay.where(relay.greater(x, y), x, y))
    #check_relay_grad(relay.argmax(x))
    #check_relay_grad(relay.argmin(X, axis=1))
    check_relay_grad(relay.sum(x))
    check_relay_grad(relay.max(x))
    check_relay_grad(relay.min(x))
    check_relay_grad(relay.mean(x))
    check_relay_grad(relay.prod(x))
    check_relay_grad(relay.strided_slice(A, (0, 4, 2, 0), (1, 1, 5, 6), (1, -1, 2, 3)))
    check_relay_grad(relay.broadcast_to(Y1, (3, 2, 5, 5)))

    check_relay_grad(relay.image.resize(A, (12, 10), method='BILINEAR'))
    check_relay_grad(relay.image.resize(A, (12, 10), method='BILINEAR', align_corners=True))
    #check_relay_grad(relay.image.resize(A, (12, 10), method='NEAREST_NEIGHBOR'))
    #check_relay_grad(relay.vision.multibox_prior(A))
    #check_relay_grad(relay.vision.multibox_transform_loc(...))
    #check_relay_grad(relay.vision.nms(...))

    check_relay_grad(relay.broadcast_to_like(Y1, Y2))
    check_relay_grad(relay.collapse_sum_like(X, x))
    t1 = relay.var("t1", shape=(3, 4, 5))
    t2 = relay.var("t2", shape=(1, 2, 3))
    check_relay_grad(relay.slice_like(t1, t2))
    check_relay_grad(relay.layout_transform(w1, 'NCHW', 'NHCW2c'))
    #check_relay_grad(relay.device_copy(...))
    #check_relay_grad(relay.annotation.on_device(...))

if __name__ == "__main__":
    test_autogenerated_primal_gradients()
